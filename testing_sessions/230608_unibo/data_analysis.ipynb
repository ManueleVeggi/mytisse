{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyTISSE. First prototype testing\n",
    "\n",
    "On June 8th, 2023 a first testing of the prototype of the \"MyTISSE\" experience was performed. It involved 24 participants, taken from an audience of Master students, PhD candidates and young researcher in the domain of Digital Humanities. See the experimental protocol for the description of the set-up of the testing session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "mytisse_data = pd.read_csv(\"data/data_cleaned.csv\", sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception of meaningfulness\n",
    "\n",
    "#### Question 1\n",
    "\n",
    "> Summarize the experience you have just participated in  focusing on the aspects you considered more relevant according to your personal experience\n",
    "\n",
    "Visitors were asked to summarize the experience, stressing more relevant elements. The following script allow to compute most frequent words applying stopwords removal and lemmatization. As for now, it provides only words occurring more than five times, yet the threshold can be changed as parameter of the function `return_topwords`. \n",
    "\n",
    "This demonstrates that the most important words are (_shape_ and _figure_ are computed together as in this context they are synonym):\n",
    "\n",
    "| Word           | Frequency      |\n",
    "|----------------|----------------|\n",
    "| painting       | 21             |\n",
    "| figure / shape | 19             |\n",
    "| color          | 13             |\n",
    "| interesting    | 9              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "painting :  21\n",
      "figure :  13\n",
      "color :  13\n",
      "interesting :  9\n",
      "work :  8\n",
      "different :  7\n",
      "shape :  6\n",
      "experience :  5\n",
      "fact :  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manuele/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK library to \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to convert dict in top-words (set threshold)\n",
    "def return_topwords(freq_dict, threshold):\n",
    "    word_counter = collections.Counter(freq_dict)\n",
    "    for word, count in word_counter.most_common():\n",
    "        if count >= threshold:\n",
    "            print(word, \": \", count)\n",
    "\n",
    "text = \" \".join(cat for cat in mytisse_data.q1).replace('\\n', '') \n",
    "\n",
    "# Prepare NLTK tools for textual pre-processing\n",
    "stopwords = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "wordcount = {} # Instantiate a dictionary\n",
    "\n",
    "# Brute force approach to calculate frequency\n",
    "\n",
    "for word in text.lower().split():\n",
    "    for char in [\".\", \",\", \":\", \"\\\"\", \"!\"]: #preprocessing: punctuation removal\n",
    "        word = word.replace(char,\"\")         \n",
    "    if word not in stopwords:               #preprocessing: stopwords removal\n",
    "        word = lemmatizer.lemmatize(word)   #preprocessing: lemmatization\n",
    "        if word not in wordcount: # Start counter\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "return_topwords(wordcount, 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following word-cloud visualizes the dataset. Please note that, being created with [Free Word Cloud Generator](https://www.freewordcloudgenerator.com/generatewordcloud), the text was not pre-processed through lemmatisation:\n",
    "\n",
    "<img src=\"viz/q1-word-cloud.png\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
